experiments:
  - model:
      layers: &id001
        - - 128
          - 256
        - - 256
          - 128
        - - 128
          - 11
      activation:
        - ReLU
      dropout:
        - 0.3
    pipeline:
      batch_size:
        - &id002
          - 256
          - 128
      num_epochs:
        - 50
    optimizer:
      type:
        - AdamW
      lr:
        - 1e-3
      weight_decay:
        - 1e-4
      momentum:
        - 0.9
      betas:
        - - 0.9
          - 0.999
      nesterov:
        - true
resize: 
  - - 16
    - 16
data_augm: True